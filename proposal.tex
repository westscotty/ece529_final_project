\documentclass[journal]{IEEEtran}
\usepackage{cite}
\usepackage{url}
\usepackage{titlesec}


% \titlespacing*{\section}{1pt}{*1}{*1} % Adjusts spacing for sections
% \titlespacing*{\subsection}{0pt}{*0}{*0} % Adjusts spacing for subsections
% \titlespacing*{\subsubsection}{0pt}{*0}{*0} % Adjusts spacing for subsubsections

\begin{document}

\title{Implementation of the Kanade-Lucas-Tomasi Feature Tracker with Python}

\author{\IEEEauthorblockN{Weston Scott}
\IEEEauthorblockA{\\University of Arizona\\ scottwj@arizona.edu}
\vspace{-10pt}
}

\maketitle

\begin{abstract}
Feature tracking is a fundamental aspect of computer vision, enabling the analysis of dynamic scenes. The Kanade-Lucas-Tomasi (KLT) feature tracker is a well-established method for tracking features across frames in video sequences. This project aims to implement the KLT tracker using Python, evaluate its performance against other tracking algorithms, and analyze its efficiency and accuracy in various scenarios in the aerial object tracking domain.
\end{abstract}

% \begin{IEEEkeywords}
% Feature tracking, Kanade-Lucas-Tomasi, optical flow, Python, computer vision.
% \end{IEEEkeywords}

\section{Introduction}
Feature tracking is essential in various applications, including object recognition, motion analysis, and augmented reality. The Kanade-Lucas-Tomasi (KLT) feature tracker, based on the principles of optical flow and feature detection, provides a robust method for tracking points in video sequences. This project will involve implementing the KLT tracker in Python and comparing its performance to alternative tracking methods.

\section{Project Description}
The proposed project will include the following steps:
\begin{itemize}
    \item \textbf{Understanding the KLT Algorithm:} Review the principles of the KLT tracker, including its reliance on optical flow and feature detection techniques.
    \item \textbf{Implementation:} Develop a Python implementation of the KLT tracker from scratch using libraries such as OpenCV and NumPy, following these key steps:
    \begin{enumerate}
        \item Convert input video frames to grayscale.
        \item Compute gradients of the image using Sobel operators (convolution kernels)
        \item Calculates scores for each pixel, helping identify strong corners.
        \item Detect key features in the first frame (and subsquent frames) using the Shi-Tomasi corner detector, which scores pixels.
        \item Select corners based on scores.
        \item Apply the Lucas-Kanade optical flow method to track features in subsequent frames which calculates the displacement of corners between frames.
        \item Visualize tracked features on the video frames.
    \end{enumerate}
    \item \textbf{Variations:} Implementation varying types/ sizes of convolution kernels for the sobel operators will be explored, in addition to image sharpening/blurring techniques.
    \item \textbf{Comparative Analysis:} Implement an alternative tracking method for performance comparison, such as the mean-shift algorithm, as well as built-in python implementations of the KLT algorithm to compare with.
\end{itemize}

% \section{References}
% Key references will include:
% \begin{itemize}
%     \item Tan, L. (2013). \textit{Digital Signal Processing}. INAOEP. Available: \url{https://www-elec.inaoep.mx/~jmram/Digital_Signal_Processing__LI_TAN.pdf}.
%     \item Wikipedia, "Kanade-Lucas-Tomasi feature tracker," \textit{Wikipedia}, 2023. [Online]. Available: \url{https://en.wikipedia.org/wiki/Kanade%E2%80%93Lucas%E2%80%93Tomasi_feature_tracker}.
%     \item Oppenheim, A. V., \& Schafer, R. W. (2010). \textit{Discrete-Time Signal Processing}, 3rd ed. Pearson.
% \end{itemize}

\section{Required Resources}
The project will require:
\begin{itemize}
    \item \textbf{Software:} Python 3.X (probably 3.12 or above), OpenCV, NumPy, Matplotlib, Scipy.
    \item \textbf{Computing Resources:} Linux-based operating system with sufficient storage and memory to handle video processing.
    \item \textbf{Test Data:} Publicly available video datasets of drones or other aircrafts following boats or other aerial vehicles (https://www.pexels.com/search/videos/). Processing the data will be required to ensure truth data can be measured against.
\end{itemize}

\section{Implementation Plan}
The plan is to use existing Python libraries (OpenCV) to load videos and convert them to grayscale, as well as display them after algorithm processing. The rest of the steps outlined in the project description are planned to be implmented from scratch using Numpy. Though this may be compuationally inefficient, it will demonstrate the step-by-step process of how the KLT algorithm works.

\section{Testing and Evaluation}
To validate the implementation, the algorithm developed from scratch will be benchmarked against existing library implementations of the KLT algorithm, and other algorithms such as the mean-shift algorithm.

\section{Conclusion}
This project will enhance understanding of feature tracking techniques while providing hands-on experience in implementing and evaluating a well-established algorithm in computer vision. By comparing the KLT tracker with alternative methods, the project will highlight the practical implications of feature tracking in real-world applications.

\bibliographystyle{IEEEtran}
\bibliography{references}

\begin{thebibliography}{1}

    \bibitem{Tan:Digital_Signal_Processing} 
    L. Tan, \textit{Digital Signal Processing}, INAOEP, 2013. [Online]. Available: \url{https://www-elec.inaoep.mx/~jmram/Digital_Signal_Processing__LI_TAN.pdf}.
    
    \bibitem{Wikipedia:KLT} 
    "Kanade-Lucas-Tomasi feature tracker," \textit{Wikipedia}, 2023. [Online]. Available: \url{https://en.wikipedia.org/wiki/Kanade%E2%80%93Lucas%E2%80%93Tomasi_feature_tracker}.
    
    \bibitem{Oppenheim:Schafer} 
    A. V. Oppenheim and R. W. Schafer, \textit{Discrete-Time Signal Processing}, 3rd ed., Pearson, 2010.

    \bibitem{KLT:Original}
    C. Kanade, T. Lucas, and B. Tomas, "An improved optical flow algorithm," in \textit{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, 1987, pp. 12-21. [Online]. Available: \url{https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6716443}.
    
    
\end{thebibliography}
    

\end{document}
